<!DOCTYPE html>
<html>

<head>
  <title>熵的解释</title>
  <meta charset="UTF-16">
  <meta name="description" content="An explorable blog post about entropy, with sheep." />
  <link rel="stylesheet" type="text/css" href="css/normalize.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
  <link rel="icon" type="image/png" href="favicon.png" sizes="32x32">
</head>
<body>

<div id="bouncingsheep" class="interactive"></div>

<div class="container">

  <div id="title">
    <h1>熵的解释，以羊为例</h1>
    <h3>从冰块融化到时间之谜</h3>
    <h3>作者：<a href="https://twitter.com/aatishb">Aatish Bhatia</a> ｜ 译者：<a href="https://github.com/bringyou">YuBinglei</a></h3>
  </div>


<p>让咱从一个小问题开始说起。</p>

<p>为什么这图看起来挺正常…</p>


<figure>
<a href="https://commons.wikimedia.org/wiki/File:Melting_icecubes.gif"><img src="media/meltingice.gif" alt="Ice melting in a glass"></a>
<figcaption> 摄影: Moussa / 公共领域</figcaption>
</figure>

<p>而这张看起来怪得很？</p>

<figure>
<img src="media/meltingice_reverse.gif" alt="Ice melting in a glass, played in reverse">
</figure>

<p>第二张动图就是第一张的倒放。但乍一看就知道是<b>假的</b>，这绝不会发生。几块冰遇热会融化；一杯水遇冷会凝固成冰，但却绝不会凝固成好几块方方正正的冰块（而是会凝固成杯型）。</p>

<p>但这就是奇怪的地方了。假想一下，我们可以（像显微镜一样）不断拉近视距，看清冰块中的各个原子和分子，并能将每个粒子的运动轨迹录制下来（动图1的轨迹），然后再倒放（动图2），我们会惊奇的看到，从物理学角度来说，第1张动图和第2张动图里，粒子们的轨迹都是“合法”的。那又为什么使得图1在生活中随处可见，而图2绝无可能发生呢？</p>

<p>不仅仅是冰块，假如将一个鸡蛋摔碎在地板上，在鸡蛋摔碎这个混乱的事件中，每个原子的运动轨迹都可以反过来，从理论上说，地板上的鸡蛋碎片可以冲向对方，聚合成一个完好的鸡蛋，然后起立穿过空气，优雅地飞回到我们手中。同样的，这个重生的鸡蛋中的原子的运动轨迹仍然符合物理学，但也同样的，碎了的鸡蛋从来没复原过。</p>

<h2>不可逆性的起源</h2>

<p>所以我们这个看似简单的冰块融化问题背后，隐藏着一个大秘密。从微观粒子的角度看，大自然并不偏爱某一种方式（冰块融化或水凝固）， 原子的世界是一个双向道。</p>

<p>当然，出于某些原因，当大量的原子聚集时，事件发生的轨迹就构成了一个单行道，尽管微观上不存在单行（的限制），时间的箭头路引就这样出现了。</p>

</div>
<figure>
<img src="media/onewaytotwoway.gif" width="700px" alt="An arrow of time emerges.">

<figcaption>
 原子世界是一个双向道，但大量原子聚集时就成了一个单行道</figcaption>
</figure>

<div class="container">
<p>为什么？</p>

<p>你也许听过这样的解释：当你摔碎一个鸡蛋、融化一块冰亦或打碎酒杯，这个世界的<b>熵</b>就增加了，也许还听过一句：“<b>熵永远增加</b>”。换句话说，事情只会朝一个方向发展——熵增加的方向。</p>

<p>但这个说话并没有解答我们的疑惑，它只是将其替换成许多的新问题罢了。</p>

<p>熵<b>到底</b>是什么？为什么熵只能增加，为什么破碎的蛋壳不会重聚，碎裂的酒杯不会复原？笔者希望通过本文的叙述，能给读者带来一些能够解释这些问题的工具</p>

<p>而沿着这条路继续走下去，将会触碰到宇宙中那些最大的未解之谜：宇宙是如何诞生的，又会如何终结？为什么我们的过去与未来截然不同？</p>

<h2>数羊</h2>

<p>那么就让我们步入正题把。首先来看张图。</p>

<figure>
<img src="media/sadsheep.jpg" width="700px" alt="Confuddled sheep.">
</figure>

<p>假设我们有3只羊，随意地跑在一个农场里，而这个农场被均分成了3个区域。</p>

<p>3只羊在3块地里随机排列，总共有10种组合，下图的羊可以被拖动，尝试把10种组合都找出来吧。</p>
</div>

<div id="arrangesheep" class="interactive"></div>

<div class="container">

<p><span class="choice" data-choicename="arrangements">找齐了吗？如果没找齐也没关系，<a href="#" class="choice-item">点击这里</a>查看所有组合</span></p>

<div class="choice-result" data-choicename="arrangements">
<span class="choice-result-item"><p>好吧，10种全在这里了：</p>
<figure>
<img src="media/10arrangements.gif" alt="10 Ways To Arrange 3 Balls in 3 Boxes">
</figure>
</span>
</div>

<p>我们为什么要引入这样一个田园牧歌呢？因为下文会用它来解释固体相关的物理现象。</p>

<p>当我们加热一个固体时，就为它注入了能量。通常认为能量是连续不断的，但当我们深入到原子领域，量子力学证实了能量是由一份一份组成的（译者注：正如物质由各个基本粒子组成，能量也是有最小组成单元，见<a href="https://zh.wikipedia.org/wiki/量子">量子</a>和<a href="https://zh.wikipedia.org/wiki/普朗克常数">普朗克常数</a>）。</p>

<p>在<a href="http://hyperphysics.phy-astr.gsu.edu/hbase/quantum/hosc.html#c1">量子图</a>中，可以把原子看作是存放能量的<a href="http://hyperphysics.phy-astr.gsu.edu/hbase/therm/einsol.html">小桶</a>，我们可以往其中放置任意数量的能量。</p>

<figure>
<img src="media/energyanalogy.png" alt="analogy between energy and sheep">
</figure>

<p>就像羊在农场里面游荡一样，能量子在固体原子中也是随机分布的。所以我们的假想农场就是固体的建模，用羊来代表能量子，用地块代表原子，羊在地块上乱跑。</p>

<p>回到农场模型，当我们有3只羊和3块地时，总共有10种组合方式，但如果有更多的羊，更多的地时，会发生什么？将会有多少种组合？点击下图的蓝色按钮试试吧。</p>

</div>

<div id="addsheep" class="interactive"></div>

<div class="container">
<p>组合数量涨得很快。</p>

<p>不难发现，随着羊或地块的增加，总的组合数目指数上涨。</p>

<p>回到现实中的固体，假如我们增加能量或原子的数目，总共的组合数会爆炸性增长。举个例子，一个固体有30个原子和30份能量（如同30只羊跑在30块地上），总共有5.9亿亿种组合方式。想想看，这才30个原子，日常我们接触到的固体大约有10^24（1亿亿亿） (a million billion billion) ，其中的能量份数也有差不多相同的量级，这使得组合数量达到了难以想象的地步。</p>

<h2>熵就是组合数</h2>

<p>看到这里，读者们可能会感到疑惑，这两者之间有什么关系呢？实际上，熵就是“潜在的组合数”的时兴说法。熵是保持一件事物外在状态（宏观）不变的前提下，可以对其内在（微观）进行重新排列的计数（实际上是这些计数的对数，但这只是数学上的简化，并不影响我们的讨论）。</p>

<p>举个例子，对于一个气球，我们可以测量出里面气体的一些确切属性——压强、体积和温度等，也就是表达它宏观状态的数据So, for example, if you gave me a balloon, I could measure certain things about the gas inside it – its pressure, volume, temperature, and so on. These numbers record the macroscopic state of the gas. Given this handful of numbers, there are umpteen ways in which the gas molecules might be arranged inside the balloon. They could have different positions, and whiz about in different directions, with different speeds. So there’s a massive number of internal, microscopic arrangements (in this case, the positions and velocities of the gas molecules) that all result in the same external state (pressure, volume, and temperature of the gas). Entropy is a count of all these arrangements.</p>

<figure>
<img src="media/insideaballoon.jpg" width="400px" alt="molecules inside a balloon">
<figcaption>The entropy of the air inside a balloon counts all the ways that the air molecules can be arranged while maintaining the same overall temperature, pressure, and volume.</figcaption>
</figure>

<p>Going back to our solid, we saw that as we made it bigger, by adding more atoms, or hotter, by adding more packets of energy, the number of possible energy arrangements blew up. In other words, the entropy increased.</p>

<p>Notice in the case of the balloon, we were talking about arrangements of gas molecules, while in the case of the solid, we’re talking about arrangements of energy packets (and in the farm, we’re arranging sheep). Entropy is all about arrangements of things, but the actual things being arranged can be different in each case.</p>

<h2>Putting The Pieces Together</h2>

<p>We can now begin to answer the question we set out with. Why does entropy increase?</p>

<p>To see why, we’re going to need two solids and stick them together. Let’s say each solid has 3 atoms. We’ll start one of them hot, with 6 packets of energy, and the other cold, with no energy. The solids can exchange energy freely between themselves.</p>

<figure>
<img src="media/einsteinsolid.gif" alt="Two Einstein Solids Exchanging Energy">
</figure>

<p>In sheep land, we’ve removed the fence between two neighboring farms, each with 3 plots of land, and 6 sheep are roaming freely between them.</p>

<p>What will happen? Click on the farm below to see for yourself.</p>
</div>

<div id="releasesheep" class="interactive"></div>

<div class="container">

<p>On the left hand side of the sheep simulation above, you can watch the sheep shuffling between the farms at random. There doesn’t seem to be any pattern to their motion.</p>

<p>On the right hand side, you'll find a graph (a histogram) that keeps track of every 'sheep state' you encounter. (The state here refers to how many sheep are in the top farm, and how many on the bottom.) And if you watch it go for a while, you'll notice something interesting.</p>

<p>It turns out, you're most likely to find the sheep more or less evenly split between the two farms (the states labelled 2, 3, or 4 on the graph). Meanwhile, states where the sheep are all in one farm (labelled 0 or 6 on the graph) aren't as likely. (If you don't see this as yet, press one of the blue buttons to speed up the simulation.)</p>

<p>So although the sheep are shuffled at random, over time, a pattern emerges. <i>Some states are more likely than others.</i></p>

<h2>Why Sheep Spread Out</h2>

<p>To see why, let’s count arrangements. Here are all the ways to arrange the sheep between the two farms.</p>
</div>

<div id="graphsheep" class="interactive"></div>

<div class="container">

<p>If you add those blue bars up, you'll find they add up to 462. So there are 462 ways to arrange the 6 sheep in this situation.</p>

<p>Now, let’s assume the sheep are equally likely to be in any of these 462 arrangements. (Since they move randomly, there's no reason to prefer one arrangement over another.) In that case, we're most likely to find the sheep evenly distributed between the two farms, because this state has the most arrangements (it's the biggest bar in the graph).</p>

<p>In physics-speak, the sheep are most likely to be in the highest entropy state.</p>

<p>Meanwhile, there are only 28 possible arrangements for the state we started off in, with all 6 sheep on the top farm (the bar to the right of the graph). So we're less likely to find the sheep in this lower entropy state.</p>

<p>It’s important to keep in mind that there’s no special guiding force driving these sheep to spread out and increase entropy. It’s just that there are fewer ways to keep the sheep concentrated, and more ways to spread them out.</p>

<figure>
<img src="media/lowvshighentropy.png" width="700px" alt="Comparing a low and high entropy state">
<figcaption>There are fewer arrangements where the sheep (energy) are concentrated, and more arrangements where the sheep (energy) are spread out. </figcaption>
</figure>

<p>Let's translate this back to the physics world. We started off with energy unequally distributed between two solids. Then we put the solids together, and let them exchange energy freely. Over time, we discovered the most likely outcome was for both solids to share the energy evenly. The hot object cooled down, and the cool object warmed up. As this happened, their entropy increased.</p>

<p>Just like for the sheep, there’s no new law of physics that ‘tells’ the energy to spread out, or the entropy to go up. There are simply more ways to spread energy out than to keep it contained, so that's what we should expect to see happen. Higher entropy states are more probable than lower entropy ones.</p>

<p>We’re beginning to see how that ‘one-way street’ emerges.</p>

<p>But, in this tiny system, odd things can happen. Here’s that graph again, showing all the different states.</p>

</div>

<div id="graphenergy" class="interactive"></div>

<div class="container">

<p>There’s something curious here. Although the equal energy state is the most likely, it’s still very possible to find all the energy in one solid (the left or right extremes of the graph). In fact, there's about a 1 in 8 chance of this happening. So the entropy in this system can fluctuate, sometimes going up, other times going down.</p>

<p>So when we look at really tiny solids, energy doesn’t always flow from a hot object to a cold one. It can go the other way sometimes. And entropy doesn’t always increase. This isn't just a theoretical issue, entropy decreases have actually been <a href ="http://www.nature.com/news/1998/020722/full/news020722-2.html">seen in microscopic experiments</a>.</p>

<h2>Why Big Is Different</h2>

<p>So what’s different about big things? To find out, turn up the number of energy packets, and then the number of atoms, and watch what happens to our arrangements graph.</p>

</div>

<div class="interactive">
	<div style = "width: 50%; min-width: 360px; margin: 0 auto;">
		<label for="amount1">Energy Packets:</label>
		<input type="text" id="amount1" readonly style="border:0; color:#f6931f; font-size:1em;">
		<div id="slider1""></div>
		<label for="amount2"> Atoms:</label>
		<input type="text" id="amount2" readonly style="border:0; color:#f6931f; font-size:1em;">
		<div id="slider2"></div>
		The odds of finding the system in the least likely state are about 1 in <input type="text" id="amount3" readonly style="border:0; color:#f6931f; font-size:1em;">
	</div>
	<div id="graphenergyinteractive"></div>
</div>

<div class="container">

<p>You should see that as you make things bigger, the graph of arrangements becomes more sharply peaked, centered around the most likely (i.e. the highest entropy) state.</p>

<p>The left and right ends of the graph represent states where the energy is mostly contained in one solid, and these become very unlikely. Meanwhile, the middle of the graph represents states where the energy is evenly distributed between both solids, and these become increasingly likely.</p>

<p>Remember that when we stuck two tiny solids together (with 3 atoms each and 6 packets of energy), there was about a 1 in 8 chance of finding all the energy concentrated in one solid. Those aren't terrible odds... you probably wouldn't bet a lot of money against this outcome.</p>

<p>But, when we scale up these solids to having 50 atoms each, and sharing 50 units of energy, the odds of finding all the energy in one solid is about 1 in <i>133 billion</i>. Now that's starting to look like a much safer bet!</p>

<figure>
<img src="media/entropygraphs.jpg" width="700px" alt="graphs of entropy as number of particles increase">
<figcaption>As you add more pieces to your system, its entropy graph becomes steeper and steeper. So you're increasingly likely to find it at a state near the peak.</figcaption>
</figure>

<p>And that’s just 50 atoms. When we get to an object as big as an ice cube in a glass of water, with something like 10^25 molecules, this entropy graph becomes incredibly sharply peaked, and you're guaranteed to be right near the peak. The odds of seeing entropy decrease are effectively zero, not because any physical law compels it to be so, but because of sheer statistics &mdash; there are overwhelmingly more ways for the energy to be spread out than there are ways for the energy to be contained.</p>

<p>We’ve just discovered why “entropy always increases”, a statement known to science as the Second Law of Thermodynamics.</p>

<h2>The Solution to Our Mystery</h2>

<p>We’ve covered a lot of ground here, so it’s worth pausing to recap. We started by asking why so many things in our lives happen in one direction, but never in reverse. Ice melts, but a glass of water on a warm day never turns into a block of ice. Eggs crack, but never uncrack; wine-glasses shatter, but never unshatter.</p>

<p>The mystery is, at the level of atoms and molecules, each of these processes are reversible. But when we get to bigger collections of atoms, a kind of one-way street emerges &mdash; a macroscopic irreversibility arises from microscopically reversible parts. Things spontaneously happen in the direction of increasing entropy, never in the opposite direction.</p>

<p>Now we know why. There’s no microscopic law telling any particle which direction to go, just like there’s no shepherd telling the sheep where to go in our imaginary farm. It’s just that there are more ways to spread energy around, and fewer ways to keep energy confined. Increasing entropy is highly likely, decreasing it is basically impossible. It’s just stuff obeying the laws of chance.</p>

<h2>Entropy and Our Lives</h2>

<p>The workings of our entire planet, including all the processes of life, ride on a wave of increasing entropy.</p>

<p>All life on Earth relies on the energy we get from the sun. Sunlight is made up of concentrated, low-entropy parcels of energy. Our planet chews up this useful energy, uses it for its inner workings, and spits out the remainder as heat &mdash; a more spread out (and therefore higher-entropy) form of energy.</p>

<p>The well from which we draw this low-entropy energy is the Sun. Like all stars, our Sun radiates away its concentrated energy, increasing its entropy, and slowly coming into equilibrium with the cold vacuum of space. One day our well will run out, as the Sun will run cold.</p>

<h2>Where Are We Going?</h2>

<p>Maybe you see where this is going. Extrapolating to the distant future, all stars will extinguish, all galaxies will radiate away their warmth, and our universe will reach a state of thermal equilibrium, no part of it any warmer or colder than any other part. Our universe will have hit peak entropy.</p>

<p>And equilibrium is a boring place. There can be no life, no machines, and no meaningful change in equilibrium. This doomsday scenario is called the heat death of the universe, and it’s how cosmologists currently expect our universe to end. But don’t lose sleep over it, it won’t happen for another googol (that’s 10^100) years, and we’ll all be dead long before (I really did start this sentence trying to help).</p>

<h2>How Did We Get Here?</h2>

<p>There’s one last mystery lurking. We learned that the entropy of our universe keeps rising, and this is because higher entropy states are more probable than lower entropy ones. Based on this, we can extrapolate that our universe must have started off in a very improbable state of very low entropy.</p>

<p>Nobody really knows why things began this way (although some folks have their guesses). But thank goodness for it, because everything interesting that has ever happened (and ever will happen) was a consequence of this unlikely beginning.</p>

<p>The story of our universe is that of climbing Mt. Entropy, beginning in the fiery low-entropic depths of the Big Bang, and making its way to the summit, a cold and barren state of thermal equilibrium. Both the base and the peak of Mt. Entropy are utterly inhospitable to life. But somewhere along those rising slopes, the conditions were just right for complex and wondrous things to emerge, things like trees and jellyfish and heartache and cheesecakes and yes, even melting cubes of ice.</p>

</div>

<div id="bouncingsheep2" class="interactive"></div>

<div class="footer">
<div class="container">

	<div class="social_outer">
	<div class="social_inner">
		<img src="media/social/share.png" height="60">
		<a href="http://www.facebook.com/sharer.php?u=https://aatishb.github.io/entropy"><img src="media/social/Facebook.png" width="60" height="60"></a>
    	<a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Faatishb.github.io%2Fentropy&amp;text=Entropy%20Explained,%20With%20Sheep&amp;via=aatishb" target="_blank"><img src="media/social/Twitter.png" width="60" height="60"></a>
    	<a href="javascript:void((function()%7Bvar%20e=document.createElement('script');e.setAttribute('type','text/javascript');e.setAttribute('charset','UTF-8');e.setAttribute('src','https://assets.pinterest.com/js/pinmarklet.js?r='+Math.random()*99999999);document.body.appendChild(e)%7D)());"><img src="media/social/Pinterest.png" width="60" height="60"></a>
		<a href="https://plus.google.com/share?url=https://aatishb.github.io/entropy" target="_blank"><img src="media/social/Google+.png" width="60" height="60"></a>
    	<a href="http://reddit.com/submit?url=https://aatishb.github.io/entropy&amp;title=Entropy Explained, With Sheep" target="_blank"><img src="media/social/Reddit.png" width="60" height="60"></a>
		<a href="https://github.com/aatishb/entropy/"><img src="media/social/Github.png" width="60" height="60"></a>
	</div>
	</div>

	<h2>Thanks for checking out this post!</h2>

	<p>If you enjoyed this essay and want to see more of this kind of work in future, please consider <b><a href="https://www.patreon.com/aatishb">supporting me on Patreon</a></b>. Your support makes this work possible.</p>

	<p>If you have any feedback, <a href="https://twitter.com/aatishb">drop me a line</a>. I'd love to hear what you think.</p>

	<h2>Learn More</h2>

	<p>The model of a solid described in this post was <a href="http://hyperphysics.phy-astr.gsu.edu/hbase/therm/einsol.html">first proposed</a> by none other than Albert Einstein <a href="https://en.wikipedia.org/wiki/Einstein_solid">in 1907</a>.</p>

	<p>If you're interested in learning about entropy at a more mathematical level, I recommend the excellent textbook <a href="https://www.amazon.com/Introduction-Thermal-Physics-Daniel-Schroeder/dp/0201380277">Thermal Physics</a> by Daniel Schroeder. This post is my take on the ideas in Chapter 2 of his book (and also summarized in <a href="http://arxiv.org/pdf/1502.07051.pdf">this paper</a>).</p>

	<p>It's a short step to go from understanding entropy to understanding temperature at a more fundamental level. I explored that link in my 2013 post, <a href="http://www.empiricalzeal.com/2013/01/05/what-the-dalai-lama-can-teach-us-about-temperatures-below-absolute-zero/">What the Dalai Lama can teach us about temperatures below absolute zero</a>.

	<p>If you want to learn more about the arrow of time, pick up Sean Carroll's 2010 book <a href="https://www.preposterousuniverse.com/eternitytohere/">From Eternity To Here</a>, or watch one of his <a href="https://www.youtube.com/results?search_query=sean+carroll+time">many excellent talks</a> on the subject. His latest book is <a href="https://www.preposterousuniverse.com/bigpicture/">The Big Picture</a>.</p>

	<p>Huge thanks to Yusra Naqvi, Upasana Roy, Jonathan Zong and Nicky Case for their helpful feedback.</p>

	<h2>Remix</h2>

	<p>This post is released in the public domain, under the <a href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons Zero</a> license. That means you can distribute, remix and adapt it however you like, without asking for permission. (Although if you do something cool with it, I'd love to hear from you.) Attribution isn't legally required, but it's always appreciated.</p>

	<p>Spot a typo? You can fix it <a href="https://github.com/aatishb/entropy/edit/master/index.html">here</a>.</p>

	<p>Here's the <a href="https://github.com/aatishb/entropy/">source code</a>, if you're into that. The interactives were built using <a href="https://p5js.org/">p5.js</a> and <a href="https://plot.ly/javascript/">plotly.js</a></p>


</div>
</div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.5.2/p5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.0.0-beta1/jquery.min.js"></script>
  <script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
  <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

  <script type="text/javascript">
   function isScrolledIntoView(elem)
  {
      var $elem = $(elem);
      var $window = $(window);

      var docViewTop = $window.scrollTop();
      var docViewBottom = docViewTop + $window.height();

      var elemTop = $elem.offset().top;
      var elemBottom = elemTop + $elem.height();

      return ((( elemTop >= docViewTop) && (elemTop <= docViewBottom)) || ((elemBottom >= docViewTop) && (elemBottom <= docViewBottom)) || (( elemTop <= docViewTop) && (elemBottom >= docViewBottom)));
  }
  </script>

  <!-- This is used to measure page speed. Not needed any more. -->
  <!-- <script type="text/javascript">javascript:(function(){var script=document.createElement('script');script.onload=function(){var stats=new Stats();stats.domElement.style.cssText='position:fixed;left:0;top:0;z-index:10000';document.body.appendChild(stats.domElement);requestAnimationFrame(function loop(){stats.update();requestAnimationFrame(loop)});};script.src='//rawgit.com/mrdoob/stats.js/master/build/stats.min.js';document.head.appendChild(script);})()
  </script> -->

  <script type="text/javascript" src="js/sketches/bouncingsheep/sketch.js"></script>
  <script type="text/javascript"> new p5(bouncingsheep, "bouncingsheep"); </script>

  <script type="text/javascript" src="js/sketches/bouncingsheep/sketch2.js"></script>
  <script type="text/javascript"> new p5(bouncingsheep2, "bouncingsheep2"); </script>

  <script type="text/javascript" src="js/sketches/arrangesheep/sketch.js"></script>
  <script type="text/javascript"> new p5(arrangesheep, "arrangesheep"); </script>

  <script type="text/javascript" src="js/sketches/addsheep/sketch.js"></script>
  <script type="text/javascript"> new p5(addsheep, "addsheep"); </script>

  <script type="text/javascript" src="js/sketches/releasesheep/sketch.js"></script>
  <script type="text/javascript"> new p5(releasesheep, "releasesheep"); </script>

  <script src="https://cdn.plot.ly/plotly-1.2.0.min.js"></script>

  <script type="text/javascript" src="js/sketches/graphsheep/sketch.js"></script>
  <script type="text/javascript"> makeGraph1(); </script>

  <script type="text/javascript" src="js/sketches/graphenergy/sketch.js"></script>
  <script type="text/javascript"> makeGraph2(); </script>

  <script type="text/javascript" src="js/sketches/graphenergyinteractive/sketch.js"></script>
  <script type="text/javascript"> makeGraph3(xarr,yarr); </script>

  <script type="text/javascript" src="js/sketches/createsliders.js"></script>

  <script type="text/javascript" src="js/libraries/forkingpaths.js"></script>


</body>


<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Entropy Explained, With Sheep">
<meta name="twitter:description" content="An explorable blog post about entropy, with sheep.">
<meta name="twitter:creator" content="@aatishb">
<!-- Twitter Summary card images must be at least 120x120px -->
<meta name="twitter:image" content="https://aatishb.github.io/entropy/media/sadsheep.jpg">

<!-- Open Graph data -->
<meta property="og:title" content="Entropy Explained, With Sheep" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://aatishb.github.io/entropy" />
<meta property="og:image" content="https://aatishb.github.io/entropy/media/sadsheep.jpg" />
<meta property="og:description" content="An explorable blog post about entropy, with sheep." />

</html>
